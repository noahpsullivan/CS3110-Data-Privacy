{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 3110/5110: Data Privacy\n",
    "## In-Class Exercise, week of 10/30/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:47:03.043069500Z",
     "start_time": "2023-11-05T01:46:57.377407500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:47:18.433999600Z",
     "start_time": "2023-11-05T01:47:06.214699600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:47:21.842368700Z",
     "start_time": "2023-11-05T01:47:21.800284100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Using scikit-learn, train a logistic regression model on the training data loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:48:59.046214500Z",
     "start_time": "2023-11-05T01:48:58.624520400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eeb7ec9241a2a7c54c5594dc4d77c69",
     "grade": true,
     "grade_id": "cell-32c8bf5cd1ba5719",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T01:49:50.773661800Z",
     "start_time": "2023-11-05T01:49:49.920751700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 4.78170133e-01 -1.79931321e-01 -3.40133603e-02  6.84523207e-02\n",
      " -5.91006819e-01 -3.66105390e-01 -1.06084670e+00 -6.69733212e-01\n",
      " -6.36881044e-01 -4.60609540e-01 -5.10585899e-01 -3.97823096e-01\n",
      " -7.57646283e-01 -7.81249016e-01  6.35796558e-02  1.18071728e-01\n",
      "  5.10755783e-01  1.00306576e+00 -1.12271824e-01  7.38195557e-01\n",
      " -1.18449574e+00  1.28199885e+00  1.10347188e-01 -8.97886249e-01\n",
      "  1.50204541e+00  1.25197643e+00 -5.83464324e-01 -1.31378111e+00\n",
      " -8.89740089e-01 -7.54431205e-01 -5.67395184e-02  5.14558992e-02\n",
      " -8.00528755e-04  7.21861649e-01 -8.96547192e-01 -6.94310123e-01\n",
      " -3.23898536e-01 -9.41107325e-01 -1.09689047e+00  4.72878928e-01\n",
      "  4.76955030e-01  2.21566753e-01  5.09572280e-01 -1.29277978e-01\n",
      " -3.74288894e-01  1.81115326e-03 -7.74189090e-01 -1.05094022e+00\n",
      " -1.90642329e-01  7.02968244e-01 -5.02458284e-01 -4.50935879e-02\n",
      " -4.88093508e-01 -4.18043863e-01 -2.31591890e-01 -1.17524508e+00\n",
      " -5.10036049e-01  8.94588254e-01  6.12571489e-01 -2.84250889e-01\n",
      " -1.27129412e+00  1.13977909e-01 -4.79601048e-01 -2.56507367e-01\n",
      " -1.84741323e-01  6.39740396e-01  8.82890498e-01  1.58722825e-02\n",
      "  4.91333885e-02  5.38345552e-02  4.10239248e-01 -1.65008399e-02\n",
      "  7.53390821e-02 -2.71865961e-01  5.79585631e-01  1.69618439e-02\n",
      "  2.56129336e-01  7.50874767e-01  7.69388567e-01  2.66355108e-01\n",
      " -8.56146051e-02 -7.43883801e-01 -5.85237207e-01 -3.65803275e-01\n",
      " -3.50575152e-01 -5.70992719e-01  2.68341285e-01  3.61992507e-02\n",
      "  3.74298692e-01 -2.17809967e-01 -9.50780823e-01 -6.53164962e-01\n",
      " -1.22537457e-01 -6.43301390e-01 -4.87936257e-01  3.02749811e-01\n",
      " -9.45918384e-01  4.33965020e-01  2.26093484e+00  1.02663416e+00\n",
      "  1.99443489e+00  1.86495306e+01  2.57234035e+00  2.74281164e+00]\n",
      "Model accuracy: 0.8447589562140646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npsul\\anaconda3\\envs\\CS3110-Data-Privacy\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    model = LogisticRegression().fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "model = train_model()\n",
    "print('Model coefficients:', model.coef_[0])\n",
    "print('Model accuracy:', np.sum(model.predict(X_test) == y_test)/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Implement the *average gradient* of the loss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:50:14.202589600Z",
     "start_time": "2023-11-05T01:50:14.184728500Z"
    }
   },
   "outputs": [],
   "source": [
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab7d67d24660b6cbf040bc661971aaa0",
     "grade": true,
     "grade_id": "cell-ace29743234ed3f6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T01:51:38.198924100Z",
     "start_time": "2023-11-05T01:51:38.171388500Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_grad(theta, X, y):\n",
    "    example_grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n",
    "    avg_grad = np.mean(example_grads, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Use the average gradient from above to implement a gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4850cab1fb79077d710818b58adf4fc",
     "grade": true,
     "grade_id": "cell-87483deb56e7ce88",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T01:53:23.978333200Z",
     "start_time": "2023-11-05T01:53:20.622109800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.63933476e-02, -2.62737908e-02, -3.76703876e-01,  5.75414219e-02,\n       -6.45755008e-02, -2.73486282e-02, -1.30672661e-03, -5.91543132e-02,\n       -7.64880798e-02, -2.62061378e-02, -1.57561761e-02, -2.86662073e-02,\n       -4.72301785e-02, -3.76260473e-02, -9.90166218e-03, -1.97245917e-02,\n        1.55177596e-01,  4.49929106e-02, -3.29796604e-01,  1.19518106e-01,\n       -4.89454322e-03,  6.88790663e-02, -1.55396891e-01, -1.80599005e-01,\n        1.54260151e-03,  3.89119966e-01, -1.97894731e-02, -5.15748994e-01,\n       -5.58626968e-02, -4.09361505e-02, -1.28065226e-01, -1.62203385e-04,\n       -1.08119029e-01,  1.88498244e-01, -6.47481586e-02, -8.66006277e-02,\n       -9.99400278e-02, -2.05565204e-01, -1.11388992e-02,  1.61706332e-01,\n       -3.59862313e-03, -1.50012146e-02,  1.68869178e-03, -5.12278071e-02,\n        3.20211424e-01, -2.99730645e-01, -6.21807885e-02, -2.79987375e-01,\n       -1.81265739e-01,  8.06793703e-02, -1.62147320e-02, -2.28589562e-02,\n       -1.37829430e-01, -1.60678844e-02, -2.29302751e-01, -3.66995428e-01,\n       -5.52783255e-02,  1.71465403e-04,  1.01657252e-03, -2.30554477e-03,\n       -4.49929315e-03, -3.16006935e-03, -5.97944101e-03, -2.17232333e-03,\n       -6.49185240e-03,  2.25224908e-03,  1.03307811e-03, -2.97354842e-03,\n        4.61969711e-06, -4.47281179e-03, -2.64817559e-03, -6.27231883e-05,\n       -8.45045871e-04, -5.36070827e-04,  9.85204107e-05,  8.18802416e-04,\n        2.81426612e-04, -1.10188120e-04, -3.16311117e-04, -4.14059871e-03,\n       -2.56618731e-04, -1.23603629e-03, -5.52492747e-02, -2.68278922e-03,\n       -1.13850454e-03, -2.58782610e-03, -4.19239246e-03, -2.31953654e-03,\n       -2.62620550e-03, -8.63337753e-03, -1.04120760e-03, -4.43136447e-03,\n        2.32630683e-04, -1.21364005e-03, -1.63560801e-03, -2.93003921e-01,\n       -5.03114545e-03, -1.89672372e-04, -7.59047983e-02, -5.58277360e-02,\n       -6.33588757e-02,  5.91506903e-02,  4.41760150e-02, -8.32223096e-02])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(iterations):\n",
    "    theta = np.zeros(104)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # calculate the gradient\n",
    "        grad = avg_grad(theta, X_train, y_train)\n",
    "        # update the model by moving in the opposite direction of the gradient\n",
    "        theta = theta + -grad\n",
    "    return theta\n",
    "\n",
    "theta = gradient_descent(10)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T01:53:26.602560500Z",
     "start_time": "2023-11-05T01:53:26.580818100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.7787483414418399"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "accuracy(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Implement a *noisy gradient descent* algorithm.\n",
    "\n",
    "1. Calculate gradients for each example\n",
    "2. Clip the gradients to have bounded $L2$ norm\n",
    "3. Sum the clipped gradients\n",
    "4. Use the Gaussian mechanism to add noise to the sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fb7218fda03e851c308317aac647b0",
     "grade": false,
     "grade_id": "cell-0b1fc630cdb8484b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T02:00:52.793430600Z",
     "start_time": "2023-11-05T02:00:47.986361400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7786377708978328\n"
     ]
    }
   ],
   "source": [
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(104)\n",
    "    noisy_count = laplace_mech(len(X_train), 1, epsilon)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # calculate the gradient\n",
    "        example_grads = [gradient(theta, xi, yi) for xi, yi in zip(X_train, y_train)]\n",
    "        \n",
    "        # enforces L2 bound on each gradient\n",
    "        clipped_grads = [L2_clip(g, 3) for g in example_grads]\n",
    "        grad_sum = np.sum(clipped_grads, axis=0)  # L2 sensitivity of 3\n",
    "        \n",
    "        # Gaussian used because it lets us take advantage of L2 sensitivity\n",
    "        noisy_grad = gaussian_mech_vec(grad_sum, 3, epsilon, delta)\n",
    "        \n",
    "        # update the model by moving in the opposite direction of the gradient\n",
    "        theta = theta + - np.array(noisy_grad) / noisy_count\n",
    "        \n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent(10, 1.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd498649d6383404040839a1ac75d0c4",
     "grade": true,
     "grade_id": "cell-abdbebcaa40aa5f7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T02:01:03.141814Z",
     "start_time": "2023-11-05T02:00:58.505103600Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "What is the *total privacy cost* of the noisy gradient descent algorithm above, and why? Argue informally that the algorithm satisfies this privacy cost. Use sequential composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01db8df655fd88392405c730527f3e64",
     "grade": true,
     "grade_id": "cell-ba58f3f4ee199481",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Sensitivity\n",
    "    - Laplace mech: it's a counting query so the sensitivity is 1\n",
    "    - Gaussian mech: it's a sum of clipped vectors. Each vector in the sum is clipped to have L2 norm of at most 3. Therefore, the L2 sensitivity of the sum is 3\n",
    "2. Composition\n",
    "    - We call the Laplace mech one and the Gaussian mech 10 times so the total privacy cost is 10epsilon + epsilon, 10delta\n",
    "3. Post-Processing\n",
    "    - We start with an initial theta that is independent of the data (all 0s) and each update to theta is based on differentially private values. So the final model satisfies differential privacy by post-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Repeat the above, but using advanced composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec1e540eb29decdc214d46eeb15c6da1",
     "grade": true,
     "grade_id": "cell-c9effbc5db1e2de3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "By advanced composition the total epsilon is 2epsilon*sqrt(2k*log(1/delta'))\n",
    "- Here k = 10\n",
    "- I set delta' = 1e-5\n",
    "- So the total epsilon for the Gaussian mechanism is 2epsilon*sqrt(2*10*log(1/1e-5))\n",
    "- The total epsilon for the whole training procedure is 2epsilon*sqrt(2*10*log(1/1e-5)) + epsilon\n",
    "- The total delta is k*delta + delta' = 10delta + 1e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Implement a version of noisy gradient descent that satisfies a *total* of $(\\epsilon, \\delta)$-differential privacy. Use sequential composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f395037ed06f9bc220e8413ebb6f6c88",
     "grade": false,
     "grade_id": "cell-a4171a5ddcc6c2b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T02:11:52.625471Z",
     "start_time": "2023-11-05T02:11:47.603242900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.777421494913755\n"
     ]
    }
   ],
   "source": [
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(104)\n",
    "    epsilon_i = epsilon / (iterations + 1)\n",
    "    delta_i = delta / iterations\n",
    "    noisy_count = laplace_mech(len(X_train), 1, epsilon)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # calculate the gradient\n",
    "        example_grads = [gradient(theta, xi, yi) for xi, yi in zip(X_train, y_train)]\n",
    "        \n",
    "        # enforces L2 bound on each gradient\n",
    "        clipped_grads = [L2_clip(g, 3) for g in example_grads]\n",
    "        grad_sum = np.sum(clipped_grads, axis=0)  # L2 sensitivity of 3\n",
    "        \n",
    "        # Gaussian used because it lets us take advantage of L2 sensitivity\n",
    "        noisy_grad = gaussian_mech_vec(grad_sum, 3, epsilon_i, delta_i)\n",
    "        \n",
    "        # update the model by moving in the opposite direction of the gradient\n",
    "        theta = theta + - np.array(noisy_grad) / noisy_count\n",
    "        \n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent(10, 1.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2865f43d86f1182e018799fdd13512a7",
     "grade": true,
     "grade_id": "cell-abd0ebcaa40aa5f7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-05T02:11:59.844638800Z",
     "start_time": "2023-11-05T02:11:54.677983600Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
